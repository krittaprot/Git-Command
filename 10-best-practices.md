# 10. Git Best Practices for ML Teams

## üéØ Learning Objectives
By the end of this section, you'll have:
- A comprehensive set of Git best practices for ML projects
- Established workflows that prevent common issues
- Team standards and conventions
- A complete ML Git workflow template
- Long-term maintenance strategies

## üèó Repository Structure Best Practices

### Standard ML Project Structure
```bash
ml-project/
‚îú‚îÄ‚îÄ .git/                    # Git repository data
‚îú‚îÄ‚îÄ .github/                 # GitHub-specific files
‚îÇ   ‚îú‚îÄ‚îÄ ISSUE_TEMPLATE/      # Issue templates
‚îÇ   ‚îú‚îÄ‚îÄ workflows/           # GitHub Actions
‚îÇ   ‚îî‚îÄ‚îÄ PULL_REQUEST_TEMPLATE.md
‚îú‚îÄ‚îÄ .gitignore              # Files to ignore
‚îú‚îÄ‚îÄ .gitattributes          # Git LFS and file handling
‚îú‚îÄ‚îÄ README.md               # Project documentation
‚îú‚îÄ‚îÄ CONTRIBUTING.md         # Contribution guidelines
‚îú‚îÄ‚îÄ LICENSE                 # Project license
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ setup.py               # Package setup
‚îú‚îÄ‚îÄ config/                # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ development/
‚îÇ   ‚îú‚îÄ‚îÄ staging/
‚îÇ   ‚îî‚îÄ‚îÄ production/
‚îú‚îÄ‚îÄ data/                  # Data files (mostly in .gitignore)
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Original data (Git LFS)
‚îÇ   ‚îú‚îÄ‚îÄ processed/        # Processed data (Git LFS)
‚îÇ   ‚îú‚îÄ‚îÄ external/         # External data sources
‚îÇ   ‚îî‚îÄ‚îÄ samples/          # Small sample datasets (Git)
‚îú‚îÄ‚îÄ models/               # Model files
‚îÇ   ‚îú‚îÄ‚îÄ experiments/      # Experimental models (Git LFS)
‚îÇ   ‚îú‚îÄ‚îÄ production/       # Production models (Git LFS)
‚îÇ   ‚îî‚îÄ‚îÄ checkpoints/      # Training checkpoints (Git LFS)
‚îú‚îÄ‚îÄ notebooks/            # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ exploratory/      # EDA notebooks
‚îÇ   ‚îú‚îÄ‚îÄ experiments/      # Experiment notebooks
‚îÇ   ‚îî‚îÄ‚îÄ final/           # Final analysis notebooks
‚îú‚îÄ‚îÄ src/                  # Source code
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data/            # Data processing modules
‚îÇ   ‚îú‚îÄ‚îÄ features/        # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ models/          # Model implementations
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/      # Model evaluation
‚îÇ   ‚îú‚îÄ‚îÄ visualization/   # Plotting and visualization
‚îÇ   ‚îî‚îÄ‚îÄ utils/          # Utility functions
‚îú‚îÄ‚îÄ tests/               # Unit tests
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_data/
‚îÇ   ‚îú‚îÄ‚îÄ test_models/
‚îÇ   ‚îî‚îÄ‚îÄ test_utils/
‚îú‚îÄ‚îÄ docs/                # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ api/            # API documentation
‚îÇ   ‚îú‚îÄ‚îÄ tutorials/      # How-to guides
‚îÇ   ‚îî‚îÄ‚îÄ experiments/    # Experiment logs
‚îî‚îÄ‚îÄ scripts/            # Utility scripts
    ‚îú‚îÄ‚îÄ train.py        # Training scripts
    ‚îú‚îÄ‚îÄ evaluate.py     # Evaluation scripts
    ‚îî‚îÄ‚îÄ deploy.py       # Deployment scripts
```

### Essential Configuration Files

#### Comprehensive .gitignore
```bash
cat > .gitignore << 'EOF'
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
env/
venv/
ENV/
env.bak/
venv.bak/
.conda/
conda-meta/

# Jupyter Notebook
.ipynb_checkpoints
*/.ipynb_checkpoints/*

# Data files (use Git LFS for large files)
*.csv
*.tsv
*.parquet
*.h5
*.hdf5
*.feather
*.arrow
data/raw/*
data/processed/*
data/external/*
!data/raw/.gitkeep
!data/processed/.gitkeep
!data/external/.gitkeep
!data/samples/

# Model files (use Git LFS)
*.pkl
*.pickle
*.joblib
*.model
*.pb
*.pth
*.pt
*.ckpt
*.h5
models/experiments/*
models/production/*
models/checkpoints/*
!models/experiments/.gitkeep
!models/production/.gitkeep
!models/checkpoints/.gitkeep

# Logs and outputs
*.log
logs/
outputs/
runs/
mlruns/
wandb/
.tensorboard/

# IDE and editors
.vscode/
.idea/
*.swp
*.swo
*~
.DS_Store
Thumbs.db

# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Temporary files
*.tmp
*.temp
*.bak
*.backup

# Environment variables
.env
.env.local
.env.*.local

# Cache directories
.cache/
.pytest_cache/
.mypy_cache/
.coverage
htmlcov/

# Documentation builds
docs/_build/
site/

# Large files and archives
*.zip
*.tar.gz
*.rar
*.7z

# Sensitive data
secrets/
credentials/
*.key
*.pem
EOF
```

#### Git LFS Configuration (.gitattributes)
```bash
cat > .gitattributes << 'EOF'
# Data files
*.csv filter=lfs diff=lfs merge=lfs -text
*.tsv filter=lfs diff=lfs merge=lfs -text
*.parquet filter=lfs diff=lfs merge=lfs -text
*.h5 filter=lfs diff=lfs merge=lfs -text
*.hdf5 filter=lfs diff=lfs merge=lfs -text
*.feather filter=lfs diff=lfs merge=lfs -text
*.arrow filter=lfs diff=lfs merge=lfs -text

# Model files
*.pkl filter=lfs diff=lfs merge=lfs -text
*.pickle filter=lfs diff=lfs merge=lfs -text
*.joblib filter=lfs diff=lfs merge=lfs -text
*.model filter=lfs diff=lfs merge=lfs -text

# Deep learning models
*.pb filter=lfs diff=lfs merge=lfs -text
*.pth filter=lfs diff=lfs merge=lfs -text
*.pt filter=lfs diff=lfs merge=lfs -text
*.ckpt filter=lfs diff=lfs merge=lfs -text

# Compressed files
*.zip filter=lfs diff=lfs merge=lfs -text
*.tar.gz filter=lfs diff=lfs merge=lfs -text
*.rar filter=lfs diff=lfs merge=lfs -text
*.7z filter=lfs diff=lfs merge=lfs -text

# Media files
*.jpg filter=lfs diff=lfs merge=lfs -text
*.jpeg filter=lfs diff=lfs merge=lfs -text
*.png filter=lfs diff=lfs merge=lfs -text
*.gif filter=lfs diff=lfs merge=lfs -text
*.tiff filter=lfs diff=lfs merge=lfs -text
*.mp4 filter=lfs diff=lfs merge=lfs -text
*.avi filter=lfs diff=lfs merge=lfs -text
*.mov filter=lfs diff=lfs merge=lfs -text
*.wav filter=lfs diff=lfs merge=lfs -text
*.mp3 filter=lfs diff=lfs merge=lfs -text

# Jupyter notebooks (optional - only if you want to track outputs)
# *.ipynb filter=lfs diff=lfs merge=lfs -text

# Line ending normalization
*.py text eol=lf
*.md text eol=lf
*.yml text eol=lf
*.yaml text eol=lf
*.json text eol=lf
*.txt text eol=lf
*.sh text eol=lf
EOF
```

## üìù Commit Message Standards

### Conventional Commits for ML
```bash
# Format: <type>(<scope>): <description>
# 
# <body>
# 
# <footer>

# Types:
# feat: New feature or capability
# fix: Bug fix
# docs: Documentation changes
# style: Code style changes (formatting, etc.)
# refactor: Code refactoring
# test: Adding or updating tests
# chore: Maintenance tasks
# experiment: ML experiment changes
# data: Data-related changes
# model: Model-related changes

# Examples:
git commit -m "feat(model): add LSTM architecture for sentiment analysis

- Implement bidirectional LSTM with attention
- Add dropout layers for regularization
- Achieve 89% accuracy on validation set

Closes #123"

git commit -m "experiment(hyperparameters): tune learning rate and batch size

Tested configurations:
- lr=0.001, batch=32: acc=0.85
- lr=0.01, batch=64: acc=0.87
- lr=0.005, batch=32: acc=0.89 (best)

Best config selected for production"

git commit -m "fix(data): resolve data leakage in preprocessing pipeline

- Move target encoding after train/test split
- Add validation checks for data integrity
- Update unit tests for preprocessing functions"

git commit -m "data: add new customer dataset for churn prediction

- 50k customer records with 25 features
- Includes demographic and behavioral data
- Stored in Git LFS due to size (150MB)"
```

### Commit Message Template
```bash
# Set up commit message template
cat > ~/.gitmessage << 'EOF'
# <type>(<scope>): <subject>
#
# <body>
#
# <footer>

# Type: feat, fix, docs, style, refactor, test, chore, experiment, data, model
# Scope: component affected (data, model, pipeline, etc.)
# Subject: imperative, present tense, no period, max 50 chars
#
# Body: explain what and why, not how (wrap at 72 chars)
#
# Footer: reference issues, breaking changes, etc.
#
# Examples:
# feat(model): add ensemble method for improved accuracy
# fix(data): resolve missing value handling in preprocessing
# experiment(tuning): compare different optimizers
# data: add validation dataset for model evaluation
EOF

# Configure Git to use the template
git config --global commit.template ~/.gitmessage
```

## üåä Branching Strategies

### ML-Specific Git Flow
```bash
# Main branches
main            # Production-ready code and models
develop         # Integration branch for experiments

# Supporting branches
feature/*       # New features and capabilities
experiment/*    # ML experiments and model development
data/*         # Data processing and pipeline changes
hotfix/*       # Critical fixes for production
release/*      # Release preparation

# Example workflow:
# 1. Create experiment branch from develop
git checkout develop
git pull origin develop
git checkout -b experiment/alice-transformer-sentiment

# 2. Work on experiment
# ... develop, train, evaluate ...
git add .
git commit -m "experiment(transformer): implement BERT-based sentiment classifier"

# 3. Push and create PR
git push origin experiment/alice-transformer-sentiment
# Create PR to develop branch

# 4. After review and merge, create release
git checkout develop
git pull origin develop
git checkout -b release/v2.0
# Prepare release, update version numbers, etc.

# 5. Merge to main and tag
git checkout main
git merge release/v2.0
git tag -a v2.0 -m "Release v2.0: BERT sentiment classifier"
git push origin main --tags
```

### Branch Naming Conventions
```bash
# Feature branches
feature/data-pipeline-optimization
feature/model-api-endpoint
feature/evaluation-metrics

# Experiment branches
experiment/alice-lstm-architecture
experiment/bob-hyperparameter-tuning
experiment/charlie-ensemble-methods

# Data branches
data/customer-segmentation-dataset
data/preprocessing-pipeline-v2
data/feature-engineering-update

# Bug fixes
fix/memory-leak-training
fix/data-validation-error
fix/model-serialization-bug

# Hotfixes
hotfix/critical-inference-bug
hotfix/security-vulnerability

# Release branches
release/v1.0
release/v2.0-beta
```

## ü§ù Team Collaboration Standards

### Code Review Checklist
```markdown
## ML Code Review Checklist

### General Code Quality
- [ ] Code is readable and well-documented
- [ ] Functions have clear docstrings
- [ ] Variable names are descriptive
- [ ] No hardcoded values (use configuration)
- [ ] Proper error handling and logging
- [ ] Code follows team style guide (PEP 8 for Python)

### Data Handling
- [ ] No data leakage between train/validation/test sets
- [ ] Proper data validation and sanity checks
- [ ] Efficient data loading and preprocessing
- [ ] Appropriate handling of missing values
- [ ] Data transformations are documented

### Model Implementation
- [ ] Model architecture is clearly defined
- [ ] Hyperparameters are configurable
- [ ] Random seeds are set for reproducibility
- [ ] Model saving/loading is implemented correctly
- [ ] Appropriate evaluation metrics are used

### Experiment Tracking
- [ ] Experiment parameters are logged
- [ ] Results are properly documented
- [ ] Comparison with baseline is included
- [ ] Reproducibility instructions are clear
- [ ] Performance claims are supported by evidence

### Testing
- [ ] Unit tests for critical functions
- [ ] Integration tests for pipelines
- [ ] Data validation tests
- [ ] Model performance regression tests

### Documentation
- [ ] README is updated if needed
- [ ] API documentation is current
- [ ] Experiment results are documented
- [ ] Breaking changes are noted

### Git Practices
- [ ] Commit messages are descriptive
- [ ] No sensitive data in commits
- [ ] Large files use Git LFS
- [ ] Branch naming follows conventions
- [ ] No merge conflicts
```

### Pull Request Template
```markdown
<!-- .github/PULL_REQUEST_TEMPLATE.md -->

## Description
Brief description of the changes and their purpose.

## Type of Change
- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] Documentation update
- [ ] ML experiment
- [ ] Data pipeline change
- [ ] Model improvement

## Experiment Results (if applicable)
### Before
- Metric 1: X.XX
- Metric 2: X.XX
- Training time: X minutes

### After
- Metric 1: X.XX (+/- X.XX)
- Metric 2: X.XX (+/- X.XX)
- Training time: X minutes (+/- X minutes)

## Testing
- [ ] Code runs without errors
- [ ] All existing tests pass
- [ ] New tests have been added
- [ ] Results are reproducible
- [ ] Documentation has been updated

## Checklist
- [ ] My code follows the team's style guidelines
- [ ] I have performed a self-review of my code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes
- [ ] Any dependent changes have been merged and published

## Related Issues
Closes #(issue number)
Related to #(issue number)

## Additional Notes
Any additional information that reviewers should know.
```

## üîß Automation and Tooling

### Pre-commit Hooks Setup
```bash
# Install pre-commit
pip install pre-commit

# Create .pre-commit-config.yaml
cat > .pre-commit-config.yaml << 'EOF'
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-json
      - id: check-added-large-files
        args: ['--maxkb=50000']  # 50MB limit
      - id: check-merge-conflict
      - id: debug-statements

  - repo: https://github.com/psf/black
    rev: 23.1.0
    hooks:
      - id: black
        language_version: python3

  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
        args: [--max-line-length=88, --extend-ignore=E203]

  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
        args: ["--profile", "black"]

  - repo: https://github.com/kynan/nbstripout
    rev: 0.6.1
    hooks:
      - id: nbstripout

  - repo: local
    hooks:
      - id: check-model-files
        name: Check model files are tracked by LFS
        entry: python scripts/check_lfs_tracking.py
        language: python
        files: \.(pkl|joblib|h5|pth|pt)$
EOF

# Install the hooks
pre-commit install

# Run on all files (optional)
pre-commit run --all-files
```

### Custom Git Aliases for ML
```bash
# Set up ML-specific Git aliases
git config --global alias.ml-init '!f() { 
  git init && 
  git lfs install && 
  curl -o .gitignore https://raw.githubusercontent.com/github/gitignore/main/Python.gitignore &&
  echo "*.pkl filter=lfs diff=lfs merge=lfs -text" >> .gitattributes &&
  echo "*.h5 filter=lfs diff=lfs merge=lfs -text" >> .gitattributes &&
  git add .gitignore .gitattributes &&
  git commit -m "Initial commit: setup ML project"; 
}; f'

git config --global alias.experiment '!f() { 
  git checkout -b experiment/$(whoami)-$1 && 
  echo "Started experiment: $1" > experiments/$(date +%Y%m%d)-$1.md &&
  git add experiments/ &&
  git commit -m "experiment: start $1"; 
}; f'

git config --global alias.model-tag '!f() { 
  git tag -a model-v$1 -m "Model version $1 - Performance: $2"; 
}; f'

git config --global alias.clean-branches '!git branch --merged | grep -v "\\*\\|main\\|develop" | xargs -n 1 git branch -d'

git config --global alias.team-summary '!f() {
  echo "=== ML Team Summary ===" &&
  echo "Active experiments:" &&
  git branch -a | grep experiment/ | head -5 &&
  echo "Recent model tags:" &&
  git tag | grep model- | tail -5 &&
  echo "Recent commits:" &&
  git log --oneline --since="1 week ago" | head -10;
}; f'

# Usage examples:
# git ml-init
# git experiment lstm-sentiment-analysis
# git model-tag 1.0 "accuracy=0.89"
# git clean-branches
# git team-summary
```

## üìä Monitoring and Maintenance

### Repository Health Monitoring
```python
#!/usr/bin/env python3
"""
Repository health check for ML projects.
"""

import subprocess
import os
from pathlib import Path

def check_repo_size():
    """Check repository size."""
    result = subprocess.run("du -sh .git/", shell=True, capture_output=True, text=True)
    size = result.stdout.split()[0] if result.stdout else "Unknown"
    print(f"Repository size: {size}")

def check_lfs_status():
    """Check Git LFS status."""
    result = subprocess.run("git lfs ls-files", shell=True, capture_output=True, text=True)
    if result.returncode == 0:
        lfs_count = len(result.stdout.split('\n')) if result.stdout else 0
        print(f"Git LFS files tracked: {lfs_count}")
    else:
        print("Git LFS not available or not initialized")

def main():
    """Run all health checks."""
    print("=== ML Repository Health Check ===")
    
    if not Path('.git').exists():
        print("Error: Not a Git repository")
        return
    
    check_repo_size()
    check_lfs_status()
    print("Health check complete!")

if __name__ == "__main__":
    main()
```

### Automated Cleanup Scripts
```bash
# Create cleanup script
cat > scripts/cleanup_repo.sh << 'EOF'
#!/bin/bash
set -e

echo "=== ML Repository Cleanup ==="

# Clean merged branches
echo "Cleaning merged branches..."
git branch --merged | grep -v "\*\|main\|develop" | xargs -n 1 git branch -d 2>/dev/null || true

# Clean up Git LFS cache
echo "Cleaning Git LFS cache..."
git lfs prune

# Run garbage collection
echo "Running Git garbage collection..."
git gc --aggressive --prune=now

# Clean notebook outputs
echo "Cleaning notebook outputs..."
if command -v nbstripout >/dev/null 2>&1; then
    find . -name "*.ipynb" -not -path "./.git/*" -exec nbstripout {} \; 2>/dev/null || true
fi

# Remove temporary files
echo "Removing temporary files..."
find . -name "*.tmp" -o -name "*.temp" -o -name "*~" -not -path "./.git/*" -delete 2>/dev/null || true

echo "Cleanup complete!"
EOF

chmod +x scripts/cleanup_repo.sh
```

## üìã Team Onboarding Checklist

### New Team Member Setup
```markdown
# ML Team Git Onboarding Checklist

## Prerequisites
- [ ] Install Git (latest version)
- [ ] Install Git LFS
- [ ] Install Python and required packages
- [ ] Set up GitHub/GitLab account with SSH keys

## Git Configuration
- [ ] Configure name and email: `git config --global user.name "Your Name"`
- [ ] Configure editor: `git config --global core.editor "your-editor"`
- [ ] Set up commit template: `git config --global commit.template ~/.gitmessage`
- [ ] Install team Git aliases (run setup script)

## Repository Setup
- [ ] Clone main repository
- [ ] Initialize Git LFS: `git lfs install`
- [ ] Install pre-commit hooks: `pre-commit install`
- [ ] Set up development environment
- [ ] Run health check script

## Team Practices
- [ ] Read CONTRIBUTING.md
- [ ] Understand branching strategy
- [ ] Review code review checklist
- [ ] Practice creating experiment branches
- [ ] Learn commit message conventions

## First Contribution
- [ ] Create a small test branch
- [ ] Make a minor change (e.g., update documentation)
- [ ] Create pull request
- [ ] Go through code review process
- [ ] Merge after approval

## Resources
- [ ] Bookmark team Git documentation
- [ ] Join team communication channels
- [ ] Schedule Git workflow walkthrough with mentor
- [ ] Review recent experiments and their Git history
```

## üéØ Long-term Maintenance

### Monthly Repository Maintenance
```bash
# Create monthly maintenance script
cat > scripts/monthly_maintenance.py << 'EOF'
#!/usr/bin/env python3
"""
Monthly maintenance tasks for ML Git repository.
"""

import subprocess
import json
from datetime import datetime, timedelta

def run_git_command(cmd):
    """Run git command and return output."""
    result = subprocess.run(f"git {cmd}", shell=True, capture_output=True, text=True)
    return result.stdout.strip(), result.returncode

def generate_monthly_report():
    """Generate monthly activity report."""
    print("=== Monthly Repository Report ===")
    print(f"Generated: {datetime.now().strftime('%Y-%m-%d')}")
    print()
    
    # Commit activity
    last_month = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
    output, _ = run_git_command(f"log --since='{last_month}' --oneline")
    commits = output.split('\n') if output else []
    print(f"Commits in last 30 days: {len(commits)}")
    
    # Active contributors
    output, _ = run_git_command(f"shortlog -sn --since='{last_month}'")
    if output:
        print("Top contributors:")
        for line in output.split('\n')[:5]:
            print(f"  {line}")
    
    # Experiment branches
    output, _ = run_git_command("branch -a")
    exp_branches = [b for b in output.split('\n') if 'experiment/' in b]
    print(f"Active experiment branches: {len(exp_branches)}")
    
    # Model tags
    output, _ = run_git_command("tag")
    model_tags = [t for t in output.split('\n') if 'model-' in t or 'v' in t]
    print(f"Model versions tagged: {len(model_tags)}")
    
    # Repository size
    output, _ = run_git_command("count-objects -vH")
    if output:
        for line in output.split('\n'):
            if 'size-pack' in line:
                print(f"Repository size: {line.split()[-1]}")
                break

def cleanup_old_branches():
    """Clean up old experiment branches."""
    # Get branches older than 60 days
    cutoff_date = (datetime.now() - timedelta(days=60)).strftime('%Y-%m-%d')
    output, _ = run_git_command(f"for-each-ref --format='%(refname:short) %(committerdate:short)' refs/heads/experiment/")
    
    old_branches = []
    if output:
        for line in output.split('\n'):
            if line:
                branch, date = line.split()
                if date < cutoff_date:
                    old_branches.append(branch)
    
    if old_branches:
        print(f"Old experiment branches found: {len(old_branches)}")
        print("Consider cleaning up:")
        for branch in old_branches[:10]:  # Show first 10
            print(f"  {branch}")

def main():
    """Run monthly maintenance."""
    generate_monthly_report()
    print()
    cleanup_old_branches()
    
    # Save report
    timestamp = datetime.now().strftime('%Y%m%d')
    with open(f"docs/monthly_reports/report_{timestamp}.md", "w") as f:
        f.write("# Monthly Repository Report\n")
        f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
        # Add more detailed report content here

if __name__ == "__main__":
    main()
EOF

chmod +x scripts/monthly_maintenance.py
```

## üìù Complete Workflow Template

### Daily ML Development Workflow
```bash
# Morning routine
git checkout main
git pull origin main
git checkout develop
git pull origin develop

# Start new experiment
git checkout -b experiment/$(whoami)-new-architecture
echo "# Experiment: New Architecture" > experiments/$(date +%Y%m%d)-new-architecture.md
git add experiments/
git commit -m "experiment: start new architecture investigation"

# During development
# ... make changes ...
git add src/models/new_model.py
git commit -m "feat(model): implement new architecture

- Add transformer-based model
- Include attention mechanism
- Initial accuracy: 0.87 on validation set"

# Push regularly
git push origin experiment/$(whoami)-new-architecture

# End of day
git add .
git commit -m "experiment: save progress on new architecture

WIP: still tuning hyperparameters
Current best: lr=0.001, batch_size=32"
git push origin experiment/$(whoami)-new-architecture

# When experiment is complete
git checkout develop
git pull origin develop
# Create PR for experiment/$(whoami)-new-architecture -> develop
```

## üìö Key Takeaways

### Essential Practices
1. **Structure**: Use consistent project structure across all ML projects
2. **Configuration**: Set up proper .gitignore and .gitattributes from the start
3. **LFS**: Use Git LFS for all large files (>50MB)
4. **Commits**: Write descriptive commit messages following conventions
5. **Branches**: Use clear branching strategy with descriptive names
6. **Reviews**: Implement thorough code review process
7. **Automation**: Use pre-commit hooks and automated checks
8. **Documentation**: Keep documentation up-to-date and accessible
9. **Monitoring**: Regular repository health checks and maintenance
10. **Training**: Proper team onboarding and continuous learning

### Success Metrics
- **Code Quality**: Consistent style, good test coverage
- **Collaboration**: Smooth PR process, minimal conflicts
- **Reproducibility**: Experiments can be easily reproduced
- **Performance**: Fast Git operations, manageable repository size
- **Knowledge Sharing**: Good documentation, effective code reviews
- **Team Velocity**: Efficient workflows, minimal Git-related delays

## üéâ Congratulations!

You've completed the comprehensive Git training for Machine Learning Engineers! You now have:

- ‚úÖ Solid understanding of Git fundamentals
- ‚úÖ ML-specific Git workflows and best practices
- ‚úÖ Experience with branching strategies for experiments
- ‚úÖ Knowledge of handling large files with Git LFS
- ‚úÖ Collaboration skills for ML teams
- ‚úÖ Advanced Git techniques for complex scenarios
- ‚úÖ Troubleshooting skills for common issues
- ‚úÖ A complete framework for ML project management

## üöÄ Next Steps

1. **Practice**: Apply these concepts to your current ML projects
2. **Customize**: Adapt the templates and workflows to your team's needs
3. **Share**: Teach these practices to your colleagues
4. **Iterate**: Continuously improve your Git workflows based on experience
5. **Stay Updated**: Keep learning about new Git features and ML best practices

Remember: Great ML engineering isn't just about models and data‚Äîit's also about the processes and tools that enable reproducible, collaborative, and maintainable work. Git is one of your most powerful tools for achieving this!

---

**Final Challenge**: Set up a complete ML project using all the best practices from this guide. Create a template repository that your team can use for future projects. Share your experience and improvements with the community! 